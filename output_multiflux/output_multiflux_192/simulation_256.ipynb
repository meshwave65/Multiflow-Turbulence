{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77c05d-eec4-4c81-8f8b-da080cd5599e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready\n",
      "[23:39:59] Building k-grid for N=256\n",
      "[23:40:03] Generating random fields and spectral transforms (sequential to limit peak memory)\n",
      "[23:40:37] Applying spectral scaling\n",
      "[23:40:50] Applying solenoidal projection\n",
      "[23:42:57] IFFT to physical space\n",
      "[23:43:03] Mean kinetic energy density: 7.298977e+17\n",
      "[23:43:34] Saved velocity_256_cpu.npz\n",
      "[23:43:34] Computing gradients (spectral differentiation)\n",
      "[00:41:56] Gradients computed\n",
      "[00:42:00] Downsampling by factor DS=4 for invariant computation\n",
      "[00:42:02] Computing lambda2 on downsampled grid (this is the most expensive step on CPU)\n",
      "[00:42:07] Invariants ready\n",
      "[00:42:07] Feature matrix shape: (262144, 4)\n",
      "[00:42:07] Running KMeans with k=12\n",
      "[00:42:39] KMeans finished in 31.8s\n",
      "[00:42:39] N_eff (cutoff 0.5%): 12\n",
      "[00:44:50] Saved CSV: output_multiflux_256_cpu/cluster_volumes_256_cpu.csv, NPZ and report\n"
     ]
    }
   ],
   "source": [
    "# Multiflux 256^3 - CPU-optimized notebook\n",
    "# License: CC BY-NC-SA 4.0\n",
    "# Paste this block into a cell (or split into logical cells at comments).\n",
    "\n",
    "# --- Imports and basic setup ---\n",
    "import os, time, gc\n",
    "import numpy as np\n",
    "from scipy.fft import fftn, ifftn, fftfreq\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "print('Environment ready')\n",
    "\n",
    "# --- Parameters (edit if needed) ---\n",
    "N = 256            # grid (full generation)\n",
    "L = 2 * np.pi\n",
    "SEED = 42\n",
    "K_CLUSTERS = 12\n",
    "DS = 4             # downsample factor for invariants (256/4=64 -> 262k samples)\n",
    "OUTDIR = 'output_multiflux_256_cpu'\n",
    "SAVE_PLOTS = True\n",
    "VERBOSE = True\n",
    "\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def log(msg):\n",
    "    if VERBOSE:\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] {msg}\")\n",
    "\n",
    "# --- 1) Build k-grid ---\n",
    "log(f\"Building k-grid for N={N}\")\n",
    "kx = 2 * np.pi * fftfreq(N, d=L/N)\n",
    "ky = 2 * np.pi * fftfreq(N, d=L/N)\n",
    "kz = 2 * np.pi * fftfreq(N, d=L/N)\n",
    "KX, KY, KZ = np.meshgrid(kx, ky, kz, indexing='ij')\n",
    "K2 = KX**2 + KY**2 + KZ**2\n",
    "K2 += 1e-30\n",
    "K = np.sqrt(K2)\n",
    "mask = K2 > 0\n",
    "\n",
    "# --- 2) Generate random spectral fields (memory-aware) ---\n",
    "log(\"Generating random fields and spectral transforms (sequential to limit peak memory)\")\n",
    "\n",
    "shape = (N, N, N)\n",
    "\n",
    "# generate and FFT each field sequentially\n",
    "u = np.random.randn(*shape)\n",
    "u_hat = fftn(u)\n",
    "del u; gc.collect()\n",
    "\n",
    "v = np.random.randn(*shape)\n",
    "v_hat = fftn(v)\n",
    "del v; gc.collect()\n",
    "\n",
    "w = np.random.randn(*shape)\n",
    "w_hat = fftn(w)\n",
    "del w; gc.collect()\n",
    "\n",
    "# apply spectral scaling (approximate kolmogorov): multiply by K**(-5/6)\n",
    "log(\"Applying spectral scaling\")\n",
    "scale = np.where(mask, K**(-5/6), 0.0)\n",
    "u_hat *= scale\n",
    "v_hat *= scale\n",
    "w_hat *= scale\n",
    "\n",
    "# solenoidal projection in spectral space\n",
    "log(\"Applying solenoidal projection\")\n",
    "k_dot = KX * u_hat + KY * v_hat + KZ * w_hat\n",
    "u_hat = u_hat - KX * (k_dot / K2)\n",
    "v_hat = v_hat - KY * (k_dot / K2)\n",
    "w_hat = w_hat - KZ * (k_dot / K2)\n",
    "del k_dot; gc.collect()\n",
    "\n",
    "# inverse transform to physical space (free spectral arrays early)\n",
    "log(\"IFFT to physical space\")\n",
    "u = np.real(ifftn(u_hat)); del u_hat; gc.collect()\n",
    "v = np.real(ifftn(v_hat)); del v_hat; gc.collect()\n",
    "w = np.real(ifftn(w_hat)); del w_hat; gc.collect()\n",
    "\n",
    "KE_mean = 0.5 * np.mean(u*u + v*v + w*w)\n",
    "log(f\"Mean kinetic energy density: {KE_mean:.6e}\")\n",
    "\n",
    "# save raw velocities (compressed)\n",
    "np.savez_compressed(os.path.join(OUTDIR, 'velocity_256_cpu.npz'), u=u, v=v, w=w)\n",
    "log(\"Saved velocity_256_cpu.npz\")\n",
    "\n",
    "# --- 3) Gradients via FFT (spectral differentiation) ---\n",
    "log(\"Computing gradients (spectral differentiation)\")\n",
    "def grad_fft_field(f):\n",
    "    fhat = fftn(f)\n",
    "    fx = np.real(ifftn(1j * KX * fhat))\n",
    "    fy = np.real(ifftn(1j * KY * fhat))\n",
    "    fz = np.real(ifftn(1j * KZ * fhat))\n",
    "    del fhat; gc.collect()\n",
    "    return fx, fy, fz\n",
    "\n",
    "du_dx, du_dy, du_dz = grad_fft_field(u)\n",
    "dv_dx, dv_dy, dv_dz = grad_fft_field(v)\n",
    "dw_dx, dw_dy, dw_dz = grad_fft_field(w)\n",
    "log(\"Gradients computed\")\n",
    "\n",
    "# --- 4) Downsample and compute invariants (memory safe) ---\n",
    "log(f\"Downsampling by factor DS={DS} for invariant computation\")\n",
    "inds = slice(0, N, DS)\n",
    "\n",
    "u_s = u[inds, inds, inds]\n",
    "v_s = v[inds, inds, inds]\n",
    "w_s = w[inds, inds, inds]\n",
    "\n",
    "du_dx_s = du_dx[inds, inds, inds]\n",
    "du_dy_s = du_dy[inds, inds, inds]\n",
    "du_dz_s = du_dz[inds, inds, inds]\n",
    "dv_dx_s = dv_dx[inds, inds, inds]\n",
    "dv_dy_s = dv_dy[inds, inds, inds]\n",
    "dv_dz_s = dv_dz[inds, inds, inds]\n",
    "dw_dx_s = dw_dx[inds, inds, inds]\n",
    "dw_dy_s = dw_dy[inds, inds, inds]\n",
    "dw_dz_s = dw_dz[inds, inds, inds]\n",
    "\n",
    "# vorticity components\n",
    "omega_x = dw_dy_s - dv_dz_s\n",
    "omega_y = du_dz_s - dw_dx_s\n",
    "omega_z = dv_dx_s - du_dy_s\n",
    "vort_mag = np.sqrt(omega_x**2 + omega_y**2 + omega_z**2)\n",
    "\n",
    "# helicity\n",
    "helicity = u_s * omega_x + v_s * omega_y + w_s * omega_z\n",
    "\n",
    "# gradient tensor A, S, Omega\n",
    "A = np.array([\n",
    "    [du_dx_s, du_dy_s, du_dz_s],\n",
    "    [dv_dx_s, dv_dy_s, dv_dz_s],\n",
    "    [dw_dx_s, dw_dy_s, dw_dz_s]\n",
    "])\n",
    "S = 0.5 * (A + np.transpose(A, (1,0,2,3,4)))\n",
    "Omega = 0.5 * (A - np.transpose(A, (1,0,2,3,4)))\n",
    "\n",
    "tr_Omega2 = np.sum(Omega**2, axis=(0,1))\n",
    "tr_S2 = np.sum(S**2, axis=(0,1))\n",
    "Q = 0.5 * (tr_Omega2 - tr_S2)\n",
    "\n",
    "# lambda2 via eigenvalues of M = S^2 + Omega^2\n",
    "log(\"Computing lambda2 on downsampled grid (this is the most expensive step on CPU)\")\n",
    "S2 = np.einsum('il...,lj...->ij...', S, S)\n",
    "Omega2 = np.einsum('il...,lj...->ij...', Omega, Omega)\n",
    "M = S2 + Omega2\n",
    "M = np.moveaxis(M, [0,1], [-2,-1])\n",
    "eigvals = np.linalg.eigvalsh(M)\n",
    "lambda2 = np.sort(eigvals, axis=-1)[..., -2]\n",
    "del M, eigvals; gc.collect()\n",
    "\n",
    "log(\"Invariants ready\")\n",
    "\n",
    "# --- 5) Feature matrix and clustering (KMeans++) ---\n",
    "features = np.column_stack([vort_mag.ravel(), Q.ravel(), lambda2.ravel(), helicity.ravel()])\n",
    "means = features.mean(axis=0)\n",
    "stds = features.std(axis=0) + 1e-12\n",
    "X = (features - means) / stds\n",
    "n_points = X.shape[0]\n",
    "log(f\"Feature matrix shape: {X.shape}\")\n",
    "\n",
    "log(f\"Running KMeans with k={K_CLUSTERS}\")\n",
    "t0 = time.time()\n",
    "kmeans = KMeans(n_clusters=K_CLUSTERS, n_init=20, max_iter=500, random_state=SEED)\n",
    "labels_flat = kmeans.fit_predict(X)\n",
    "t1 = time.time()\n",
    "log(f\"KMeans finished in {t1-t0:.1f}s\")\n",
    "\n",
    "labels_ds = labels_flat.reshape((N//DS, N//DS, N//DS))\n",
    "\n",
    "# volumes and N_eff\n",
    "counts = np.bincount(labels_flat, minlength=K_CLUSTERS)\n",
    "volumes = counts / float(labels_flat.size)\n",
    "N_eff = int(np.sum(counts > 0.005 * labels_flat.size))\n",
    "log(f\"N_eff (cutoff 0.5%): {N_eff}\")\n",
    "\n",
    "# --- 6) Save outputs (CSV, NPZ, report) ---\n",
    "csv_path = os.path.join(OUTDIR, 'cluster_volumes_256_cpu.csv')\n",
    "with open(csv_path, 'w') as f:\n",
    "    f.write('cluster_id,count,volume_fraction\\n')\n",
    "    for cid, cnt, vol in zip(range(K_CLUSTERS), counts, volumes):\n",
    "        f.write(f'{cid},{int(cnt)},{vol:.8f}\\n')\n",
    "\n",
    "np.savez_compressed(os.path.join(OUTDIR, 'multiflux_256_cpu.npz'),\n",
    "                    u=u, v=v, w=w,\n",
    "                    vort_mag=vort_mag, Q=Q, lambda2=lambda2, helicity=helicity,\n",
    "                    labels_ds=labels_ds,\n",
    "                    meta=dict(N=N, L=L, seed=SEED, k_clusters=K_CLUSTERS, DS=DS))\n",
    "report_path = os.path.join(OUTDIR, 'report.txt')\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write('Multiflux HIT 256 run report\\n')\n",
    "    f.write(f'Grid: {N}^3; L={L}; seed={SEED}; k_clusters={K_CLUSTERS}\\n')\n",
    "    f.write(f'Mean kinetic energy density: {KE_mean:.6e}\\n')\n",
    "    f.write(f'N_eff (cutoff 0.50%): {N_eff}\\n')\n",
    "    f.write('Top 5 cluster volumes (%): ' + ', '.join(f'{100*v:.2f}' for v in sorted(volumes, reverse=True)[:5]) + '\\n')\n",
    "\n",
    "log(f\"Saved CSV: {csv_path}, NPZ and report\")\n",
    "\n",
    "# --- 7) Visualization (approximate upsample of labels for display) ---\n",
    "n = N // DS\n",
    "labels_full_approx = np.repeat(np.repeat(np.repeat(labels_ds, DS, axis=0), DS, axis=1), DS, axis=2)\n",
    "labels_full_approx = labels_full_approx[:N, :N, :N]\n",
    "mid = N // 2\n",
    "\n",
    "fig, axes = plt.subplots(2,2, figsize=(14,12))\n",
    "axes[0,0].imshow(labels_full_approx[:, :, mid], origin='lower', interpolation='nearest')\n",
    "axes[0,0].set_title('Slice XY (approx)')\n",
    "axes[0,1].imshow(labels_full_approx[:, mid, :].T, origin='lower', interpolation='nearest')\n",
    "axes[0,1].set_title('Slice XZ (approx)')\n",
    "axes[1,0].imshow(labels_full_approx[mid, :, :].T, origin='lower', interpolation='nearest')\n",
    "axes[1,0].set_title('Slice YZ (approx)')\n",
    "axes[1,1].bar(np.arange(K_CLUSTERS), volumes*100)\n",
    "axes[1,1].set_title('Cluster volumes (%)')\n",
    "\n",
    "plt.suptitle(f'Multiflux 256 CPU (DS={DS}) â€” N_eff={N_eff}')\n",
    "plt.tight_layout(rect=[0,0.03,1,0.95])\n",
    "fig_path = os.path.join(OUTDIR, 'multiflux_slices_and_hist_256_cpu.png')\n",
    "plt.savefig(fig_path, dpi=200, bbox_inches='tight')\n",
    "if SAVE_PLOTS:\n",
    "    plt.show()\n",
    "plt.close()\n",
    "log(f\"Saved figure to {fig_path}\")\n",
    "\n",
    "print('\\\\n=== SUMMARY ===')\n",
    "print(f'Grid: {N}^3, Downsample DS={DS} => feature grid {(N//DS)}^3')\n",
    "print(f'Mean KE density: {KE_mean:.6e}')\n",
    "print(f'N_eff (cutoff 0.5%): {N_eff}')\n",
    "print('Top 5 cluster volumes (%):', ', '.join(f'{100*v:.2f}' for v in sorted(volumes, reverse=True)[:5]))\n",
    "print('Outputs saved to:', OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade04a7f-deae-4181-9b8a-2da9e1247665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ff3c3-182e-4aa8-911e-15e02d268c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
