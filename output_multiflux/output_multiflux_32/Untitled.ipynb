{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cee30a1-ea7d-4ada-98b9-dbab62afecf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing request:\n",
      " Dataset: isotropic1024_fine\n",
      " Cube indices i0..i1: 448..575 (NX=128)\n",
      " Physical coords x: 2.748894 .. 3.534292\n",
      " Time t = 5.0\n",
      "\n",
      "*** NOTE ***\n",
      "This script is a template. If you do not have the pyJHTDB client installed,\n",
      "please perform the matching request in the JHTDB web interface using these parameters:\n",
      " - Dataset: isotropic1024_fine\n",
      " - Field: velocity\n",
      " - Spatial operator: gradient\n",
      " - Choose spatial method in this order of preference: m2q8, fd8noint, fd6noint, m1q4, fd4noint\n",
      " - Temporal method: none (snapshot)\n",
      " - Spatial limits: use indices 448..575 in x,y,z (central cube) OR coords 2.748894..3.534292\n",
      " - Time t = 5.0\n",
      "\n",
      "After you obtain the raw arrays (velocity and optionally gradient),\n",
      "place them in an HDF5 file with datasets: '/velocity' and '/gradA' and then re-run the\n",
      "invariant computation section below (uncommented).\n",
      "This template will then compute vorticity, Q, lambda2 and save outputs.\n",
      "\n",
      "HDF5 file src/analysis/jhtdb/isotropic1024_fine_center_128c_t5.00.h5 not found. Please run the JHTDB request first (web UI or client) and\n",
      "save the returned arrays to the above path with datasets 'velocity' and optionally 'gradA'.\n",
      "Exiting template.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mesh/Multiflow-Turbulence/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Download a central cube from JHTDB (isotropic1024_fine) with gradient operator.\n",
    "Choose spatialMethod automatically: prefer m2q8, fallback to fd8noint, fd6noint.\n",
    "Saves HDF5 with velocity and gradient (if available) and computes invariants (vort, Q, lambda2).\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# ---------- USER PARAMETERS ----------\n",
    "DATASET = \"isotropic1024_fine\"   # change if your dataset has another exact name\n",
    "NX = 128                         # cube size (128 recommended)\n",
    "T = 5.0                          # snapshot time (in dataset units)\n",
    "SPATIAL_OPERATOR = \"gradient\"    # request gradients from server if possible\n",
    "PREFERRED_METHODS = [\"m2q8\", \"fd8noint\", \"fd6noint\", \"m1q4\", \"fd4noint\"]\n",
    "OUTDIR = \"src/analysis/jhtdb\"\n",
    "OUTNAME = f\"{DATASET}_center_{NX}c_t{T:.2f}.h5\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "OUTPATH = os.path.join(OUTDIR, OUTNAME)\n",
    "# -------------------------------------\n",
    "\n",
    "# Helper: compute central index bounds for N=1024\n",
    "N_FULL = 1024\n",
    "i0 = N_FULL//2 - NX//2\n",
    "i1 = i0 + NX - 1\n",
    "\n",
    "# Physical coords (if client needs coords)\n",
    "L = 2.0 * np.pi\n",
    "dx = L / N_FULL\n",
    "x0 = i0 * dx\n",
    "x1 = (i1 + 1) * dx\n",
    "# same for y,z (centered cube)\n",
    "y0, y1 = x0, x1\n",
    "z0, z1 = x0, x1\n",
    "\n",
    "print(\"Preparing request:\")\n",
    "print(f\" Dataset: {DATASET}\")\n",
    "print(f\" Cube indices i0..i1: {i0}..{i1} (NX={NX})\")\n",
    "print(f\" Physical coords x: {x0:.6f} .. {x1:.6f}\")\n",
    "print(f\" Time t = {T}\")\n",
    "\n",
    "# ---------- Attempt to use pyJHTDB / JHTDB client ----------\n",
    "# If you have the official python client installed, uncomment and use it.\n",
    "# Installation (if available): pip install py_jhtdb   (package name may vary)\n",
    "#\n",
    "# from JHTDB import JHTDBClient   # <--- adjust this import to your installed client\n",
    "#\n",
    "# client = JHTDBClient()\n",
    "# available_methods = client.list_spatial_methods(dataset=DATASET, op=SPATIAL_OPERATOR)\n",
    "# print(\"Available spatial methods:\", available_methods)\n",
    "#\n",
    "# # choose method\n",
    "# chosen = None\n",
    "# for m in PREFERRED_METHODS:\n",
    "#     if m in available_methods:\n",
    "#         chosen = m\n",
    "#         break\n",
    "# if chosen is None:\n",
    "#     raise RuntimeError(\"No preferred spatial method available. Check available_methods.\")\n",
    "# print(\"Chosen spatial method:\", chosen)\n",
    "#\n",
    "# # Request block (client API will vary; adapt below)\n",
    "# # Example pseudo-call (replace with actual client call):\n",
    "# # data = client.getData(dataset=DATASET, field='velocity', \n",
    "# #                      spatialOperator=SPATIAL_OPERATOR, spatialMethod=chosen,\n",
    "# #                      temporalMethod='none', x=[x0,x1], y=[y0,y1], z=[z0,z1], t=T)\n",
    "#\n",
    "# # Expect 'data' to contain arrays for velocity and gradient if requested.\n",
    "# # Then save to HDF5 and compute invariants as below.\n",
    "\n",
    "# ---------- Fallback: Prompt user to perform request via JHTDB web UI ----------\n",
    "print(\"\\n*** NOTE ***\")\n",
    "print(\"This script is a template. If you do not have the pyJHTDB client installed,\")\n",
    "print(\"please perform the matching request in the JHTDB web interface using these parameters:\")\n",
    "print(f\" - Dataset: {DATASET}\")\n",
    "print(f\" - Field: velocity\")\n",
    "print(f\" - Spatial operator: {SPATIAL_OPERATOR}\")\n",
    "print(\" - Choose spatial method in this order of preference:\", \", \".join(PREFERRED_METHODS))\n",
    "print(f\" - Temporal method: none (snapshot)\")\n",
    "print(f\" - Spatial limits: use indices {i0}..{i1} in x,y,z (central cube) OR coords {x0:.6f}..{x1:.6f}\")\n",
    "print(f\" - Time t = {T}\")\n",
    "print(\"\\nAfter you obtain the raw arrays (velocity and optionally gradient),\")\n",
    "print(\"place them in an HDF5 file with datasets: '/velocity' and '/gradA' and then re-run the\")\n",
    "print(\"invariant computation section below (uncommented).\")\n",
    "print(\"This template will then compute vorticity, Q, lambda2 and save outputs.\")\n",
    "\n",
    "# ---------- If you already have HDF5 with velocity (and optionally gradA), compute invariants ----------\n",
    "# For convenience, the script below will look for an HDF5 at OUTPATH. If found, it will process it.\n",
    "if not os.path.exists(OUTPATH):\n",
    "    print(f\"\\nHDF5 file {OUTPATH} not found. Please run the JHTDB request first (web UI or client) and\")\n",
    "    print(\"save the returned arrays to the above path with datasets 'velocity' and optionally 'gradA'.\")\n",
    "    print(\"Exiting template.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "print(\"Found HDF5 file, loading and computing invariants...\")\n",
    "\n",
    "with h5py.File(OUTPATH, 'r+') as f:\n",
    "    vel = f['velocity'][:]   # shape (NX,NX,NX,3)\n",
    "    has_grad = 'gradA' in f\n",
    "    if has_grad:\n",
    "        gradA = f['gradA'][:]  # shape (NX,NX,NX,3,3)\n",
    "    else:\n",
    "        gradA = None\n",
    "\n",
    "# If gradA not present, compute gradients numerically (central FD) -- expensive\n",
    "if gradA is None:\n",
    "    print(\"gradA not found: computing numerical gradients via spectral/FD (may be slow).\")\n",
    "    # naive finite differences (periodic) as fallback:\n",
    "    u = vel[...,0]; v = vel[...,1]; w = vel[...,2]\n",
    "    # compute derivatives along each axis using numpy.gradient (not as accurate as server)\n",
    "    du_dx, du_dy, du_dz = np.gradient(u, dx, dx, dx, edge_order=2)\n",
    "    dv_dx, dv_dy, dv_dz = np.gradient(v, dx, dx, dx, edge_order=2)\n",
    "    dw_dx, dw_dy, dw_dz = np.gradient(w, dx, dx, dx, edge_order=2)\n",
    "    gradA = np.empty((NX,NX,NX,3,3), dtype=u.dtype)\n",
    "    gradA[...,0,0] = du_dx; gradA[...,0,1] = du_dy; gradA[...,0,2] = du_dz\n",
    "    gradA[...,1,0] = dv_dx; gradA[...,1,1] = dv_dy; gradA[...,1,2] = dv_dz\n",
    "    gradA[...,2,0] = dw_dx; gradA[...,2,1] = dw_dy; gradA[...,2,2] = dw_dz\n",
    "\n",
    "# Compute invariants\n",
    "# vorticity magnitude ||omega||\n",
    "Omega = 0.5 * (gradA - np.swapaxes(gradA, -1, -2))  # shape (...,3,3)\n",
    "S = 0.5 * (gradA + np.swapaxes(gradA, -1, -2))\n",
    "\n",
    "# vorticity vector (omega_i = eps_{ijk} A_{kj})\n",
    "omega_x = gradA[...,2,1] - gradA[...,1,2]\n",
    "omega_y = gradA[...,0,2] - gradA[...,2,0]\n",
    "omega_z = gradA[...,1,0] - gradA[...,0,1]\n",
    "vort_mag = np.sqrt(omega_x**2 + omega_y**2 + omega_z**2)\n",
    "\n",
    "# traces\n",
    "tr_O2 = np.sum(Omega**2, axis=(-2,-1))\n",
    "tr_S2 = np.sum(S**2, axis=(-2,-1))\n",
    "Q = 0.5 * (tr_O2 - tr_S2)\n",
    "\n",
    "# lambda2: compute eigenvalues of S^2 + Omega^2 (small 3x3 matrices)\n",
    "# Build M = S^2 + Omega^2 at each point\n",
    "M = np.einsum('...ij,...jk->...ik', S, S) + np.einsum('...ij,...jk->...ik', Omega, Omega)\n",
    "# reshape to (-1,3,3) for eig calc\n",
    "Mflat = M.reshape(-1,3,3)\n",
    "eigvals = np.linalg.eigvalsh(Mflat)\n",
    "# second largest eigenvalue (lambda2)\n",
    "lambda2_flat = np.sort(eigvals, axis=1)[:,1]\n",
    "lambda2 = lambda2_flat.reshape(NX,NX,NX)\n",
    "\n",
    "# Save invariants back to HDF5\n",
    "with h5py.File(OUTPATH, 'a') as f:\n",
    "    if 'vorticity' not in f:\n",
    "        f.create_dataset('vorticity', data=vort_mag, compression='gzip')\n",
    "    if 'Q' not in f:\n",
    "        f.create_dataset('Q', data=Q, compression='gzip')\n",
    "    if 'lambda2' not in f:\n",
    "        f.create_dataset('lambda2', data=lambda2, compression='gzip')\n",
    "\n",
    "print(\"Invariants computed and saved to HDF5. Next: run clustering / kmeans on these fields.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed8b53-be37-4d47-afc4-d67e98cf190e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
