{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7803f5ad-3a27-4dc2-afb0-6f2237763bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building k-grid for N=64, L=6.283185307179586 ...\n",
      "Generating raw Fourier amplitudes (random phases) ...\n",
      "Applying preliminary shell scaling and per-shell normalization to match E(k) ~ k^-5/3 ...\n",
      "Applying solenoidal projection in Fourier space ...\n",
      "Enforcing Hermitian symmetry (F(-k) = conj(F(k))) ...\n",
      "IFFT to physical space ...\n",
      "Field generated — mean kinetic energy density: 7.850622e-06\n",
      "Computing gradients via spectral differentiation ...\n",
      "Computing invariants: vorticity magnitude, Q, lambda2 ...\n",
      "Preparing features and standardizing ...\n",
      "Running KMeans with k=12 ...\n",
      "\n",
      "--- Results ---\n",
      "N_eff (cutoff 0.50%): 12\n",
      "Top5 cluster volumes (%): 14.87, 13.24, 11.76, 11.64, 11.51\n",
      "Saved cluster volumes to output_multiflux/cluster_volumes.csv\n",
      "Generating figures (slices and histograms) ...\n",
      "Saved figure to output_multiflux/multiflux_slices_and_hist.png\n",
      "Saved dataset to output_multiflux/multiflux_data.npz\n",
      "Saved report to output_multiflux/report.txt\n",
      "\n",
      "Run complete. Outputs in folder: output_multiflux\n",
      "Multiflux HIT synthetic run report\n",
      "Grid: 64^3; L=6.283185307179586; seed=42; k_clusters=12\n",
      "Mean kinetic energy density: 7.850622e-06\n",
      "N_eff (cutoff 0.50%): 12\n",
      "Top 5 cluster volumes (%): 14.87, 13.24, 11.76, 11.64, 11.51\n",
      "N_eff vs cutoffs:\n",
      "  cutoff 0.10% -> N_eff = 12\n",
      "  cutoff 0.20% -> N_eff = 12\n",
      "  cutoff 0.50% -> N_eff = 12\n",
      "  cutoff 1.00% -> N_eff = 12\n",
      "  cutoff 2.00% -> N_eff = 11\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "This work is licensed under the **Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)88\n",
    "\n",
    "Multiflux Theory — Prova de conceito numérica (versão aprimorada)\n",
    "Melhorias incluídas:\n",
    " - Normalização por conchas k para aproximar espectro E(k) ~ k^{-5/3}\n",
    " - Projeção solenoidal correta\n",
    " - Cálculo de invariantes locais: |ω|, Q, λ2\n",
    " - Clusterização KMeans + análise de N_eff sobre vários cortes volumétricos\n",
    " - Múltiplos slices (x, y, z), histograma de volumes e CSV de volumes\n",
    " - Parâmetros ajustáveis e saída organizada\n",
    "Dependências: numpy, scipy, scikit-learn, matplotlib\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.fft import fftn, ifftn, fftfreq\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# -----------------------\n",
    "# Configuração (edite conforme necessário)\n",
    "# -----------------------\n",
    "N = 64                 # grid N^3\n",
    "L = 2 * np.pi          # domínio [0, L]^3\n",
    "SEED = 42\n",
    "K_CLUSTERS = 12\n",
    "VOLUME_CUTOFFS = [0.001, 0.002, 0.005, 0.01, 0.02]  # frações do domínio para testar N_eff\n",
    "SAVE_DIR = \"output_multiflux\"\n",
    "SAVE_FIG = True\n",
    "SAVE_CSV = True\n",
    "VERBOSE = True\n",
    "\n",
    "# Cria diretório de saída com timestamp\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "meta = {\n",
    "    \"N\": N,\n",
    "    \"L\": L,\n",
    "    \"seed\": SEED,\n",
    "    \"k_clusters\": K_CLUSTERS,\n",
    "    \"volume_cutoffs\": VOLUME_CUTOFFS,\n",
    "    \"timestamp\": datetime.datetime.utcnow().isoformat() + \"Z\"\n",
    "}\n",
    "with open(os.path.join(SAVE_DIR, \"meta.json\"), \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# -----------------------\n",
    "# 1) Construir rede de wavenumbers\n",
    "# -----------------------\n",
    "if VERBOSE: print(f\"Building k-grid for N={N}, L={L} ...\")\n",
    "kx = 2 * np.pi * fftfreq(N, d=L/N)\n",
    "ky = 2 * np.pi * fftfreq(N, d=L/N)\n",
    "kz = 2 * np.pi * fftfreq(N, d=L/N)\n",
    "KX, KY, KZ = np.meshgrid(kx, ky, kz, indexing='ij')\n",
    "K2 = KX**2 + KY**2 + KZ**2\n",
    "# small offset to avoid division by zero\n",
    "K2 += 1e-30\n",
    "K = np.sqrt(K2)\n",
    "\n",
    "# compute magnitude flattened for shell binning\n",
    "k_flat = K.ravel()\n",
    "k_nonzero = k_flat[k_flat > 0]\n",
    "kmin = k_nonzero.min()\n",
    "kmax = k_nonzero.max()\n",
    "\n",
    "# choose number of shells (roughly N/2)\n",
    "n_shells = int(np.ceil(np.sqrt(3) * (N//2)))\n",
    "# define shell edges linearly in k\n",
    "shell_edges = np.linspace(kmin, kmax, n_shells+1)\n",
    "# compute shell index per mode\n",
    "k_shell_idx = np.digitize(K, bins=shell_edges)  # values 0..n_shells\n",
    "\n",
    "# -----------------------\n",
    "# 2) gerar amplitudes complexas aleatórias e impor espectro alvo\n",
    "# -----------------------\n",
    "if VERBOSE: print(\"Generating raw Fourier amplitudes (random phases) ...\")\n",
    "# 3 component random complex field\n",
    "amp = (np.random.randn(3, N, N, N) + 1j * np.random.randn(3, N, N, N))\n",
    "\n",
    "# Desired spectral shape: E(k) ~ k^{-5/3}\n",
    "# We'll enforce shellwise normalization so that the integrated power per shell scales like k^{-5/3}.\n",
    "if VERBOSE: print(\"Applying preliminary shell scaling and per-shell normalization to match E(k) ~ k^-5/3 ...\")\n",
    "\n",
    "# compute current power per shell\n",
    "power_shell = np.zeros(n_shells + 2, dtype=np.float64)  # accommodate indices\n",
    "count_shell = np.zeros_like(power_shell, dtype=int)\n",
    "\n",
    "amp_power = np.sum(np.abs(amp)**2, axis=0)  # shape (N,N,N)\n",
    "for idx in range(1, n_shells+1):\n",
    "    mask_shell = (k_shell_idx == idx)\n",
    "    count = np.count_nonzero(mask_shell)\n",
    "    if count == 0:\n",
    "        continue\n",
    "    count_shell[idx] = count\n",
    "    power_shell[idx] = amp_power[mask_shell].sum()\n",
    "\n",
    "# desired power per shell ~ k_center^{-5/3}\n",
    "shell_centers = 0.5 * (shell_edges[:-1] + shell_edges[1:])\n",
    "desired_power_shell = np.zeros_like(power_shell)\n",
    "for idx in range(1, n_shells+1):\n",
    "    kc = shell_centers[idx-1]\n",
    "    if kc <= 0:\n",
    "        desired_power_shell[idx] = 0.0\n",
    "    else:\n",
    "        desired_power_shell[idx] = kc**(-5/3)\n",
    "\n",
    "# avoid zero division and normalize desired_power_shell to total current power\n",
    "# only for shells that have counts\n",
    "available = (count_shell > 0)\n",
    "desired_power_shell[~available] = 0.0\n",
    "total_desired = desired_power_shell.sum()\n",
    "total_current = power_shell.sum()\n",
    "if total_desired <= 0 or total_current <= 0:\n",
    "    raise RuntimeError(\"Empty spectral power or invalid desired spectrum.\")\n",
    "# scale desired to match total current power\n",
    "scale_factor = total_current / total_desired\n",
    "desired_power_shell *= scale_factor\n",
    "\n",
    "# Now adjust amplitudes per shell: multiply modes in shell by sqrt(desired_power / current_power)\n",
    "amp_adjust = np.ones_like(amp[0])\n",
    "for idx in range(1, n_shells+1):\n",
    "    mask_shell = (k_shell_idx == idx)\n",
    "    if not np.any(mask_shell):\n",
    "        continue\n",
    "    curr = power_shell[idx]\n",
    "    want = desired_power_shell[idx]\n",
    "    if curr <= 0:\n",
    "        g = 0.0\n",
    "    else:\n",
    "        g = np.sqrt(want / curr)\n",
    "    amp_adjust[mask_shell] = g\n",
    "\n",
    "# apply adjustment to all 3 components\n",
    "amp *= amp_adjust\n",
    "\n",
    "# -----------------------\n",
    "# 3) projeção solenoidal (remover componente compressível)\n",
    "# -----------------------\n",
    "if VERBOSE: print(\"Applying solenoidal projection in Fourier space ...\")\n",
    "# compute k · amp\n",
    "k_dot_amp = KX * amp[0] + KY * amp[1] + KZ * amp[2]   # shape (N,N,N)\n",
    "# projection: amp_i -> amp_i - k_i * (k · amp) / |k|^2\n",
    "amp[0] = amp[0] - KX * (k_dot_amp / K2)\n",
    "amp[1] = amp[1] - KY * (k_dot_amp / K2)\n",
    "amp[2] = amp[2] - KZ * (k_dot_amp / K2)\n",
    "\n",
    "# ensure Hermitian symmetry so field is real in physical space\n",
    "# For real fields, Fourier coefficients must satisfy: F(-k) = conj(F(k))\n",
    "# We'll enforce symmetry by averaging with its conjugate at mirrored index.\n",
    "if VERBOSE: print(\"Enforcing Hermitian symmetry (F(-k) = conj(F(k))) ...\")\n",
    "def enforce_hermitian(field_hat):\n",
    "    # field_hat shape (N,N,N)\n",
    "    fh = field_hat.copy()\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            for k in range(N):\n",
    "                ip = (-i) % N\n",
    "                jp = (-j) % N\n",
    "                kp = (-k) % N\n",
    "                # average: set fh[ip,jp,kp] = conj(fh[i,j,k])\n",
    "                fh[ip, jp, kp] = np.conj(fh[i, j, k])\n",
    "    return fh\n",
    "\n",
    "# apply per-component\n",
    "amp[0] = enforce_hermitian(amp[0])\n",
    "amp[1] = enforce_hermitian(amp[1])\n",
    "amp[2] = enforce_hermitian(amp[2])\n",
    "\n",
    "# -----------------------\n",
    "# 4) converter para espaço físico (velocidade)\n",
    "# -----------------------\n",
    "if VERBOSE: print(\"IFFT to physical space ...\")\n",
    "u = np.real(ifftn(amp[0]))\n",
    "v = np.real(ifftn(amp[1]))\n",
    "w = np.real(ifftn(amp[2]))\n",
    "\n",
    "KE_mean = 0.5 * np.mean(u*u + v*v + w*w)\n",
    "if VERBOSE: print(f\"Field generated — mean kinetic energy density: {KE_mean:.6e}\")\n",
    "\n",
    "# -----------------------\n",
    "# 5) cálculo de gradientes via FFT\n",
    "# -----------------------\n",
    "if VERBOSE: print(\"Computing gradients via spectral differentiation ...\")\n",
    "def grad_fft(f):\n",
    "    fhat = fftn(f)\n",
    "    fx = np.real(ifftn(1j * KX * fhat))\n",
    "    fy = np.real(ifftn(1j * KY * fhat))\n",
    "    fz = np.real(ifftn(1j * KZ * fhat))\n",
    "    return fx, fy, fz\n",
    "\n",
    "du_dx, du_dy, du_dz = grad_fft(u)\n",
    "dv_dx, dv_dy, dv_dz = grad_fft(v)\n",
    "dw_dx, dw_dy, dw_dz = grad_fft(w)\n",
    "\n",
    "# gradient tensor A_{ij} = ∂u_i/∂x_j  (shape 3x3xN x N x N)\n",
    "A = np.array([[du_dx, du_dy, du_dz],\n",
    "              [dv_dx, dv_dy, dv_dz],\n",
    "              [dw_dx, dw_dy, dw_dz]])\n",
    "\n",
    "# -----------------------\n",
    "# 6) invariantes locais: vorticidade, Q, lambda2\n",
    "# -----------------------\n",
    "if VERBOSE: print(\"Computing invariants: vorticity magnitude, Q, lambda2 ...\")\n",
    "omega_x = dw_dy - dv_dz\n",
    "omega_y = du_dz - dw_dx\n",
    "omega_z = dv_dx - du_dy\n",
    "vort_mag = np.sqrt(omega_x**2 + omega_y**2 + omega_z**2)\n",
    "\n",
    "S = 0.5 * (A + np.transpose(A, (1,0,2,3,4)))\n",
    "Omega = 0.5 * (A - np.transpose(A, (1,0,2,3,4)))\n",
    "\n",
    "tr_Omega2 = np.sum(Omega**2, axis=(0,1))\n",
    "tr_S2 = np.sum(S**2, axis=(0,1))\n",
    "Q = 0.5 * (tr_Omega2 - tr_S2)\n",
    "\n",
    "# compute M = S^2 + Omega^2 and its eigenvalues to get lambda2\n",
    "S2 = np.einsum('il...,lj...->ij...', S, S)\n",
    "Omega2 = np.einsum('il...,lj...->ij...', Omega, Omega)\n",
    "M = S2 + Omega2\n",
    "# reorder M to shape (N,N,N,3,3)\n",
    "M = np.moveaxis(M, [0,1], [-2,-1])\n",
    "eigvals = np.linalg.eigvalsh(M)   # shape (N,N,N,3)\n",
    "# second largest eigenvalue\n",
    "lambda2 = np.sort(eigvals, axis=-1)[..., -2]\n",
    "\n",
    "# -----------------------\n",
    "# 7) preparação dos dados para clusterização\n",
    "# -----------------------\n",
    "if VERBOSE: print(\"Preparing features and standardizing ...\")\n",
    "features = np.column_stack([vort_mag.ravel(), Q.ravel(), lambda2.ravel()])\n",
    "# robust standardization (z-score)\n",
    "means = features.mean(axis=0)\n",
    "stds = features.std(axis=0) + 1e-12\n",
    "X = (features - means) / stds\n",
    "\n",
    "# -----------------------\n",
    "# 8) KMeans clustering\n",
    "# -----------------------\n",
    "if VERBOSE: print(f\"Running KMeans with k={K_CLUSTERS} ...\")\n",
    "kmeans = KMeans(n_clusters=K_CLUSTERS, n_init=20, max_iter=500, random_state=SEED)\n",
    "labels_flat = kmeans.fit_predict(X)\n",
    "labels = labels_flat.reshape((N, N, N))\n",
    "\n",
    "unique, counts = np.unique(labels_flat, return_counts=True)\n",
    "volumes = counts / labels_flat.size  # fraction of domain per cluster\n",
    "# sort descending\n",
    "order = np.argsort(counts)[::-1]\n",
    "top5 = volumes[order][:5] * 100\n",
    "\n",
    "# N_eff computation for default cutoff (0.5%)\n",
    "default_cut = 0.005\n",
    "N_eff_default = np.sum(counts > default_cut * labels_flat.size)\n",
    "\n",
    "if VERBOSE:\n",
    "    print(\"\\n--- Results ---\")\n",
    "    print(f\"N_eff (cutoff {default_cut*100:.2f}%): {N_eff_default}\")\n",
    "    print(\"Top5 cluster volumes (%): \" + \", \".join(f\"{v:.2f}\" for v in top5))\n",
    "\n",
    "# Evaluate N_eff across requested cutoff list\n",
    "N_eff_vs_cut = {}\n",
    "for c in VOLUME_CUTOFFS:\n",
    "    N_eff_vs_cut[c] = int(np.sum(counts > c * labels_flat.size))\n",
    "\n",
    "# -----------------------\n",
    "# 9) Save volumes CSV and metadata\n",
    "# -----------------------\n",
    "if SAVE_CSV:\n",
    "    csv_path = os.path.join(SAVE_DIR, \"cluster_volumes.csv\")\n",
    "    header = \"cluster_id,count,volume_fraction\\n\"\n",
    "    with open(csv_path, \"w\") as f:\n",
    "        f.write(header)\n",
    "        for cid, cnt in zip(unique, counts):\n",
    "            f.write(f\"{int(cid)},{int(cnt)},{cnt/labels_flat.size:.8f}\\n\")\n",
    "    if VERBOSE: print(f\"Saved cluster volumes to {csv_path}\")\n",
    "\n",
    "meta.update({\n",
    "    \"KE_mean\": float(KE_mean),\n",
    "    \"N_eff_default\": int(N_eff_default),\n",
    "    \"N_eff_vs_cut\": N_eff_vs_cut,\n",
    "    \"top5_volumes_pct\": [float(x) for x in (top5.tolist())]\n",
    "})\n",
    "with open(os.path.join(SAVE_DIR, \"meta.json\"), \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "# -----------------------\n",
    "# 10) Visualizações: slices (xy, xz, yz), histogram de volumes\n",
    "# -----------------------\n",
    "if VERBOSE: print(\"Generating figures (slices and histograms) ...\")\n",
    "mid = N // 2\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# xy slice at mid z\n",
    "im0 = axes[0,0].imshow(labels[:, :, mid], origin='lower', interpolation='nearest')\n",
    "axes[0,0].set_title(f\"Slice XY (z={mid})\")\n",
    "axes[0,0].set_xlabel(\"x\"); axes[0,0].set_ylabel(\"y\")\n",
    "cbar0 = plt.colorbar(im0, ax=axes[0,0], fraction=0.046, pad=0.04)\n",
    "cbar0.set_label(\"Subflux ID\")\n",
    "\n",
    "# xz slice at mid y\n",
    "im1 = axes[0,1].imshow(labels[:, mid, :].T, origin='lower', interpolation='nearest')\n",
    "axes[0,1].set_title(f\"Slice XZ (y={mid})\")\n",
    "axes[0,1].set_xlabel(\"x\"); axes[0,1].set_ylabel(\"z\")\n",
    "cbar1 = plt.colorbar(im1, ax=axes[0,1], fraction=0.046, pad=0.04)\n",
    "cbar1.set_label(\"Subflux ID\")\n",
    "\n",
    "# yz slice at mid x\n",
    "im2 = axes[1,0].imshow(labels[mid, :, :].T, origin='lower', interpolation='nearest')\n",
    "axes[1,0].set_title(f\"Slice YZ (x={mid})\")\n",
    "axes[1,0].set_xlabel(\"y\"); axes[1,0].set_ylabel(\"z\")\n",
    "cbar2 = plt.colorbar(im2, ax=axes[1,0], fraction=0.046, pad=0.04)\n",
    "cbar2.set_label(\"Subflux ID\")\n",
    "\n",
    "# histogram of cluster volumes\n",
    "axes[1,1].bar(np.arange(len(counts)), volumes*100)\n",
    "axes[1,1].set_title(\"Cluster volumes (%)\")\n",
    "axes[1,1].set_xlabel(\"cluster id (sorted by label index)\")\n",
    "axes[1,1].set_ylabel(\"volume (%)\")\n",
    "axes[1,1].set_ylim(0, max(volumes*100)*1.2)\n",
    "\n",
    "plt.suptitle(f\"Multiflux Theory — Instantaneous decomposition (N={N})\\nN_eff={N_eff_default} (cutoff {default_cut*100:.2f}%)\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "fig_path = os.path.join(SAVE_DIR, \"multiflux_slices_and_hist.png\")\n",
    "if SAVE_FIG:\n",
    "    plt.savefig(fig_path, dpi=200, bbox_inches='tight')\n",
    "if VERBOSE: print(f\"Saved figure to {fig_path}\")\n",
    "\n",
    "# also save individual slice images for convenience\n",
    "plt.close()\n",
    "\n",
    "# individual saves\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(labels[:, :, mid], origin='lower', interpolation='nearest')\n",
    "plt.title(f\"Slice XY (z={mid})\")\n",
    "plt.xlabel(\"x\"); plt.ylabel(\"y\")\n",
    "plt.colorbar(label=\"Subflux ID\")\n",
    "p = os.path.join(SAVE_DIR, \"slice_xy.png\"); plt.savefig(p, dpi=200, bbox_inches='tight'); plt.close()\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(labels[:, mid, :].T, origin='lower', interpolation='nearest')\n",
    "plt.title(f\"Slice XZ (y={mid})\")\n",
    "plt.xlabel(\"x\"); plt.ylabel(\"z\")\n",
    "plt.colorbar(label=\"Subflux ID\")\n",
    "p = os.path.join(SAVE_DIR, \"slice_xz.png\"); plt.savefig(p, dpi=200, bbox_inches='tight'); plt.close()\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(labels[mid, :, :].T, origin='lower', interpolation='nearest')\n",
    "plt.title(f\"Slice YZ (x={mid})\")\n",
    "plt.xlabel(\"y\"); plt.ylabel(\"z\")\n",
    "plt.colorbar(label=\"Subflux ID\")\n",
    "p = os.path.join(SAVE_DIR, \"slice_yz.png\"); plt.savefig(p, dpi=200, bbox_inches='tight'); plt.close()\n",
    "\n",
    "# -----------------------\n",
    "# 11) Salvar dados essenciais (numpy .npz) para reprodução\n",
    "# -----------------------\n",
    "npz_path = os.path.join(SAVE_DIR, \"multiflux_data.npz\")\n",
    "np.savez_compressed(npz_path,\n",
    "                    u=u, v=v, w=w,\n",
    "                    vort_mag=vort_mag, Q=Q, lambda2=lambda2,\n",
    "                    labels=labels, counts=counts, volumes=volumes,\n",
    "                    meta=meta)\n",
    "if VERBOSE: print(f\"Saved dataset to {npz_path}\")\n",
    "\n",
    "# -----------------------\n",
    "# 12) Relatório rápido em texto\n",
    "# -----------------------\n",
    "report = []\n",
    "report.append(\"Multiflux HIT synthetic run report\")\n",
    "report.append(f\"Grid: {N}^3; L={L}; seed={SEED}; k_clusters={K_CLUSTERS}\")\n",
    "report.append(f\"Mean kinetic energy density: {KE_mean:.6e}\")\n",
    "report.append(f\"N_eff (cutoff {default_cut*100:.2f}%): {N_eff_default}\")\n",
    "report.append(\"Top 5 cluster volumes (%): \" + \", \".join(f\"{v:.2f}\" for v in top5))\n",
    "report.append(\"N_eff vs cutoffs:\")\n",
    "for c, neff in N_eff_vs_cut.items():\n",
    "    report.append(f\"  cutoff {c*100:.2f}% -> N_eff = {neff}\")\n",
    "report_text = \"\\n\".join(report)\n",
    "txt_path = os.path.join(SAVE_DIR, \"report.txt\")\n",
    "with open(txt_path, \"w\") as f:\n",
    "    f.write(report_text)\n",
    "if VERBOSE: print(f\"Saved report to {txt_path}\")\n",
    "\n",
    "if VERBOSE:\n",
    "    print(\"\\nRun complete. Outputs in folder:\", SAVE_DIR)\n",
    "    print(report_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d793f-545d-4b2e-bbb9-ed6f17d82029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea79d8-e01d-432c-8a19-2ee30f42656c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
